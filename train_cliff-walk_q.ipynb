{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ParallelEnvironment\n",
    "import Worker\n",
    "import Estimator_Cliff_Walk\n",
    "from ParallelEnvironment import *\n",
    "from Worker import *\n",
    "from Estimator_Cliff_Walk import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.envs.cliff_walking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport ParallelEnvironment\n",
    "%aimport Worker\n",
    "%aimport Estimator_Cliff_Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Provider:\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "    def create(self):\n",
    "        env = Environment(CliffWalkingEnv(),self.counter,False)\n",
    "        self.counter += 1\n",
    "        return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "provider = Provider()\n",
    "parallel = ParallelEnvironment(provider, 32, 8, 4)\n",
    "estimator = Estimator(4, 48, 64, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_epsilon(step):\n",
    "    return 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_q_targets(estimator, states, rewards, done):\n",
    "    next_max_q_values = np.max(estimator.predict_q_values(states), axis= 1)\n",
    "    next_max_q_values[done == 1] = 0\n",
    "    q_targets = rewards + next_max_q_values\n",
    "    return q_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(env, estimator, num_global_steps):\n",
    "    shared_states, shared_rewards, shared_done, shared_actions = env.get_shared_variables()\n",
    "    \n",
    "    for i in range(num_global_steps):\n",
    "        if ((i+1) % 1000) == 0:\n",
    "            print(\"curr step: {}\".format(i+1))\n",
    "        epsilon = get_epsilon(i)\n",
    "        actions = estimator.choose_e_greedy_actions(shared_states, epsilon)\n",
    "        old_states = np.copy(shared_states)\n",
    "        #print(\"shared states before actions:\")\n",
    "        #print(shared_states)\n",
    "        #print(\"------------ \\n\")\n",
    "        #print(\"actions to be performed: \")\n",
    "        #print(actions)\n",
    "        #print(\"------------ \\n\")\n",
    "        env.step(actions)\n",
    "        #print(\"check whether actions and internal actions are equivalent: \")\n",
    "        #print(np.argmax(shared_actions) == actions)\n",
    "        #print(\"external actions: \")\n",
    "        #print(actions)\n",
    "        #print(\"internal actions\")\n",
    "        #print(shared_actions)\n",
    "        #print(\"------------ \\n\")\n",
    "        #print(\"shared states:\")\n",
    "        #print(shared_states)\n",
    "        #print(\"------------ \\n\")\n",
    "        q_targets = calculate_q_targets(estimator, shared_states, shared_rewards, shared_done)\n",
    "        #print(\"q targets: \")\n",
    "        #print(q_targets)\n",
    "        loss = estimator.update(old_states, actions, q_targets)\n",
    "        #print(\"loss: \"+ str(loss))\n",
    "    return estimator\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr step: 1000\n",
      "curr step: 2000\n",
      "curr step: 3000\n",
      "curr step: 4000\n",
      "curr step: 5000\n",
      "curr step: 6000\n",
      "curr step: 7000\n",
      "curr step: 8000\n",
      "curr step: 9000\n",
      "curr step: 10000\n",
      "curr step: 11000\n",
      "curr step: 12000\n",
      "curr step: 13000\n",
      "curr step: 14000\n",
      "curr step: 15000\n",
      "curr step: 16000\n",
      "curr step: 17000\n",
      "curr step: 18000\n",
      "curr step: 19000\n",
      "curr step: 20000\n",
      "curr step: 21000\n",
      "curr step: 22000\n",
      "curr step: 23000\n",
      "curr step: 24000\n",
      "curr step: 25000\n"
     ]
    }
   ],
   "source": [
    "estimator = train(parallel, estimator, 25000)\n",
    "# 3000 steps is sufficient with 32 envs sometimes takes longer, dont fiddle with the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-15.6539259 , -91.29176331, -20.53508949, -21.19099426]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict_q_values([36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(estimator, env, num_episodes):\n",
    "    for i in range(num_episodes):\n",
    "        print(\"episode nr: {}\".format(i))\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode = []\n",
    "        while not done:\n",
    "            action = estimator.choose_greedy_actions([state])[0]\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            episode.append((state, action, reward, next_state))\n",
    "            state = next_state\n",
    "        \n",
    "        print(\"episodenlänge: {}\".format(len(episode)))\n",
    "        print(\"episode reward: {}\".format(sum([transition[2] for transition in episode])))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode nr: 0\n",
      "episodenlänge: 15\n",
      "episode reward: -15.0\n",
      "episode nr: 1\n",
      "episodenlänge: 15\n",
      "episode reward: -15.0\n",
      "episode nr: 2\n",
      "episodenlänge: 15\n",
      "episode reward: -15.0\n",
      "episode nr: 3\n",
      "episodenlänge: 15\n",
      "episode reward: -15.0\n",
      "episode nr: 4\n",
      "episodenlänge: 15\n",
      "episode reward: -15.0\n",
      "episode nr: 5\n",
      "episodenlänge: 15\n",
      "episode reward: -15.0\n",
      "episode nr: 6\n",
      "episodenlänge: 15\n",
      "episode reward: -15.0\n",
      "episode nr: 7\n",
      "episodenlänge: 15\n",
      "episode reward: -15.0\n",
      "episode nr: 8\n",
      "episodenlänge: 15\n",
      "episode reward: -15.0\n",
      "episode nr: 9\n",
      "episodenlänge: 15\n",
      "episode reward: -15.0\n"
     ]
    }
   ],
   "source": [
    "eval_model(estimator, CliffWalkingEnv(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-20.12506104, -15.20067406, -19.74595451, -19.5741291 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict_q_values([24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = CliffWalkingEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print(state)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  x  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action = estimator.choose_greedy_actions([state])\n",
    "state,reward, done, info = env.step(action[0])\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action = estimator.choose_greedy_actions([state])\n",
    "print(action)\n",
    "env.step(action[0])\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action = estimator.choose_greedy_actions([state])\n",
    "print(action)\n",
    "env.step(action[0])\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states, rewards, done ,actions = parallel.get_shared_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 36, 36, 36, 36, 36, 36, 36], dtype=uint32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
